{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UACj9HvRJWtb"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "\n",
        "import os, time, math, string, re\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, Bidirectional, GRU, GlobalMaxPool1D  \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdladWIb4fTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b745fe5-4f7d-4f9c-b334-a3de6ebb4a66"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGZKx1AJJYvn"
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/Colab Folder/Quora Insincere Question/train.csv\") \n",
        "test = pd.read_csv(\"/content/drive/MyDrive/Colab Folder/Quora Insincere Question/test.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "YB1xybaJJYye",
        "outputId": "15a5eb5b-6b2e-48a2-bc27-c4c67d1c6107"
      },
      "source": [
        "print(\"Shape of train is :\", train.shape)\n",
        "train.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train is : (1306122, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... target\n",
              "0  00002165364db923c7e6  ...      0\n",
              "1  000032939017120e6e44  ...      0\n",
              "2  0000412ca6e4628ce2cf  ...      0\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "eHxFiUY5JY02",
        "outputId": "0cda0d53-dff7-42e6-da18-487defbc760f"
      },
      "source": [
        "print(\"Shape of test is :\", test.shape)\n",
        "test.head(3) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of test is : (375806, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>Why do so many women become so rude and arroga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>When should I apply for RV college of engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>What is it really like to be a nurse practitio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid                                      question_text\n",
              "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
              "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
              "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "msyEa3maJY3p",
        "outputId": "a983156a-521d-4544-8cc4-4b55e7221946"
      },
      "source": [
        "target_count = train['target'].value_counts()\n",
        "\n",
        "trace = go.Bar(\n",
        "    x=target_count.index,\n",
        "    y=target_count.values,\n",
        "    marker=dict(\n",
        "        color=target_count.values,\n",
        "        colorscale='Picnic',\n",
        "        reversescale=True\n",
        "    ),\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Target Count',\n",
        "    font=dict(size=18)\n",
        ")\n",
        "\n",
        "data = [trace]\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.iplot(fig, filename='TargetCount')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"1fe7a9a3-08e8-4b02-b862-40281435416c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"1fe7a9a3-08e8-4b02-b862-40281435416c\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '1fe7a9a3-08e8-4b02-b862-40281435416c',\n",
              "                        [{\"marker\": {\"color\": [1225312, 80810], \"colorscale\": [[0.0, \"rgb(0,0,255)\"], [0.1, \"rgb(51,153,255)\"], [0.2, \"rgb(102,204,255)\"], [0.3, \"rgb(153,204,255)\"], [0.4, \"rgb(204,204,255)\"], [0.5, \"rgb(255,255,255)\"], [0.6, \"rgb(255,204,255)\"], [0.7, \"rgb(255,153,255)\"], [0.8, \"rgb(255,102,204)\"], [0.9, \"rgb(255,102,102)\"], [1.0, \"rgb(255,0,0)\"]], \"reversescale\": true}, \"type\": \"bar\", \"x\": [0, 1], \"y\": [1225312, 80810]}],\n",
              "                        {\"font\": {\"size\": 18}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Target Count\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1fe7a9a3-08e8-4b02-b862-40281435416c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "zrQ3dbIQJY6V",
        "outputId": "5fa47014-6668-4bd3-afb2-a449fcdd8e09"
      },
      "source": [
        "labels = (np.array(target_count.index))\n",
        "sizes = (np.array((target_count/target_count.sum()) * 100))\n",
        "\n",
        "trace = go.Pie(labels=labels, values=sizes)\n",
        "layout = go.Layout(\n",
        "    title='Target distribution',\n",
        "    font=dict(size=18),\n",
        "    width=600,\n",
        "    height=600\n",
        ")\n",
        "\n",
        "data = [trace]\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "py.iplot(fig, filename='usertype')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"3f0cedd4-7b7d-4307-816e-f095736ab7ec\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"3f0cedd4-7b7d-4307-816e-f095736ab7ec\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '3f0cedd4-7b7d-4307-816e-f095736ab7ec',\n",
              "                        [{\"labels\": [0, 1], \"type\": \"pie\", \"values\": [93.81298224821265, 6.187017751787352]}],\n",
              "                        {\"font\": {\"size\": 18}, \"height\": 600, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Target distribution\"}, \"width\": 600},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3f0cedd4-7b7d-4307-816e-f095736ab7ec');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5yw9BK0Juc8"
      },
      "source": [
        "# Data Preprocessing for Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exe4d-e3Jy9P"
      },
      "source": [
        "I want to illustrate how I do come up with meaningful preprocessing when building deep learning NLP models.\n",
        "\n",
        "I start with two golden rules:\n",
        "### 1. Don't use standard preprocessing steps like stemming or stopword removal when you have pre-trained embeddings\n",
        "\n",
        "Some of you might used standard preprocessing steps when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc. The reason is simple: You loose valuable information, which would help your NN to figure things out.\n",
        "### 2. Get your vocabulary as close to the embeddings as possible\n",
        "\n",
        "I will focus in this notebook, how to achieve that.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkCqUq3qJY87"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
        "                       \"cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
        "                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \n",
        "                       \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
        "                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \n",
        "                       \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n",
        "                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \n",
        "                       \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \n",
        "                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
        "                       \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n",
        "                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
        "                       \"it'd've\": \"it would have\", \"it'll\": \"it will\", \n",
        "                       \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n",
        "                       \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
        "                       \"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
        "                       \"must've\": \"must have\", \"mustn't\": \"must not\", \n",
        "                       \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n",
        "                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
        "                       \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \n",
        "                       \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n",
        "                       \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
        "                       \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n",
        "                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \n",
        "                       \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
        "                       \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
        "                       \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \n",
        "                       \"that'd've\": \"that would have\", \"that's\": \"that is\", \n",
        "                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \n",
        "                       \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \n",
        "                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
        "                       \"they'll've\": \"they will have\", \"they're\": \"they are\", \n",
        "                       \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
        "                       \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \n",
        "                       \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n",
        "                       \"weren't\": \"were not\", \"what'll\": \"what will\", \n",
        "                       \"what'll've\": \"what will have\", \"what're\": \"what are\",  \n",
        "                       \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
        "                       \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
        "                       \"where've\": \"where have\", \"who'll\": \"who will\", \n",
        "                       \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \n",
        "                       \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n",
        "                       \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
        "                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
        "                       \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \n",
        "                       \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n",
        "                       \"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\",\n",
        "                       \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
        "                       \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
        "\n",
        "def clean_contractions(text, mapping):\n",
        "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
        "    for s in specials:\n",
        "        text = text.replace(s, \"'\")\n",
        "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
        "    return text\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4CRyYt7JY_d"
      },
      "source": [
        "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
        "\n",
        "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \n",
        "                 \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', \n",
        "                 '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', \n",
        "                 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', \n",
        "                 'π': 'pi', }\n",
        "\n",
        "def clean_special_chars(text, punct, mapping):\n",
        "    for p in mapping:\n",
        "        text = text.replace(p, mapping[p])\n",
        "    \n",
        "    for p in punct:\n",
        "        text = text.replace(p, f' {p} ')\n",
        "    \n",
        "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  # Other special characters that I have to deal with in last\n",
        "    for s in specials:\n",
        "        text = text.replace(s, specials[s])\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdl5KJplJZCF"
      },
      "source": [
        "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', \n",
        "                'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', \n",
        "                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', \n",
        "                'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', \n",
        "                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist',\n",
        "                'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', \n",
        "                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', \n",
        "                'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', \n",
        "                'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', \n",
        "                'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', \n",
        "                '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n",
        "                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', \n",
        "                'demonitisation': 'demonetization', 'demonitization': 'demonetization', \n",
        "                'demonetisation': 'demonetization', 'pokémon': 'pokemon'}\n",
        "\n",
        "def correct_spelling(x, dic):\n",
        "    for word in dic.keys():\n",
        "        x = x.replace(word, dic[word])\n",
        "    return x\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi4L_YZmJZEd"
      },
      "source": [
        "# Converting to lower case\n",
        "train['question_text'] = train['question_text'].apply(lambda x: x.lower())\n",
        "\n",
        "# Clean contrction\n",
        "train['question_text'] = train['question_text'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
        "\n",
        "# Special Character\n",
        "train['question_text'] = train['question_text'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))\n",
        "\n",
        "# Spelling mistakes\n",
        "train['question_text'] = train['question_text'].apply(lambda x: correct_spelling(x, mispell_dict))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjjf2GvTKGUA"
      },
      "source": [
        "# What you need to do for more cleaning/preprocessing?\n",
        "\n",
        "    Remove unknown word\n",
        "    Replace acronyms with a same meaning word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edpP36fWlqhB"
      },
      "source": [
        "## some config values \n",
        "embed_size = 300 \n",
        "max_features = 50000 \n",
        "maxlen = 100 "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQdWPvuFJZHW"
      },
      "source": [
        "X = train['question_text'].values\n",
        "y = train['target'].values \n",
        "\n",
        "test_x = test['question_text'].values  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZeFUhyKJZJu"
      },
      "source": [
        "train_x, valid_x, train_y, valid_y = train_test_split(X, y, \n",
        "                                                      test_size=.1, \n",
        "                                                      random_state=42,\n",
        "                                                      stratify=y\n",
        "                                                     )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s87GplW8ZKYJ",
        "outputId": "8346c579-fb4e-4ca5-abc0-18a5a5133af0"
      },
      "source": [
        "print(len(train_x), len(valid_x), len(train_y), len(valid_y))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1175509 130613 1175509 130613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMynI33ueF9C"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "#full_text = list(train_x) + list(valid_x) \n",
        "tokenizer.fit_on_texts(train_x) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcndffB8eF_9"
      },
      "source": [
        "train_x = tokenizer.texts_to_sequences(train_x)\n",
        "valid_x = tokenizer.texts_to_sequences(valid_x)\n",
        "test_x = tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "\n",
        "## Pad the sentences \n",
        "train_x = pad_sequences(train_x, maxlen=maxlen)\n",
        "valid_x = pad_sequences(valid_x, maxlen=maxlen)\n",
        "test_x = pad_sequences(test_x, maxlen=maxlen)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oB7xJxMKOUP"
      },
      "source": [
        "# using Glove Pretrained Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmcfQhU4KXiT"
      },
      "source": [
        "We have four different types of embeddings.\n",
        "\n",
        "GoogleNews-vectors-negative300 - https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "glove.840B.300d - https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "paragram_300_sl999 - https://cogcomp.org/page/resource_view/106\n",
        "\n",
        "wiki-news-300d-1M - https://fasttext.cc/docs/en/english-vectors.html\n",
        "\n",
        "A very good explanation for different types of embeddings are given in this kernel. Please refer the same for more details..\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-_nDzF_OOgN"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXuIkqCIJZMh",
        "outputId": "0d1e1089-d4a5-47f9-d3cb-d901c6a25122"
      },
      "source": [
        "glove_emb = '/content/drive/MyDrive/Colab Folder/Quora Insincere Question/glove.840B.300d.txt' \n",
        "\n",
        "def get_coefs(word,*arr): \n",
        "  return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(glove_emb))\n",
        "\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning:\n",
            "\n",
            "arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ8yw2-pJZPI"
      },
      "source": [
        "input = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size)(input)\n",
        "x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=input, outputs=x)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GyDVyVzJZR9"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfGY0erzJZUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9ee1b2-c128-460c-fd78-8bda7d12c3eb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100, 128)          140544    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 15,142,625\n",
            "Trainable params: 15,142,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xmDO7oVJZXM"
      },
      "source": [
        "checkpoints = ModelCheckpoint('weight.hdf5', \n",
        "                               monitor='val_loss', \n",
        "                               mode='max', \n",
        "                               verbose=True, \n",
        "                               save_best_only=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                              factor=0.1, \n",
        "                              patience=2, \n",
        "                              verbose=1, \n",
        "                              min_lr=0.000001)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib89dIv7JZZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebabda8-50a4-4d02-eb29-5985d8f5ba4d"
      },
      "source": [
        "history = model.fit(train_x, train_y, \n",
        "          batch_size=512, \n",
        "          epochs=12, \n",
        "          validation_data=(valid_x, valid_y),\n",
        "          callbacks=[checkpoints, reduce_lr])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "2296/2296 [==============================] - 694s 288ms/step - loss: 0.1531 - accuracy: 0.9465 - val_loss: 0.1085 - val_accuracy: 0.9566\n",
            "\n",
            "Epoch 00001: val_loss improved from -inf to 0.10849, saving model to weight.hdf5\n",
            "Epoch 2/12\n",
            "2296/2296 [==============================] - 650s 283ms/step - loss: 0.0983 - accuracy: 0.9608 - val_loss: 0.1059 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.10849\n",
            "Epoch 3/12\n",
            "2296/2296 [==============================] - 641s 279ms/step - loss: 0.0822 - accuracy: 0.9670 - val_loss: 0.1132 - val_accuracy: 0.9577\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.10849 to 0.11317, saving model to weight.hdf5\n",
            "Epoch 4/12\n",
            "2296/2296 [==============================] - 653s 285ms/step - loss: 0.0660 - accuracy: 0.9738 - val_loss: 0.1306 - val_accuracy: 0.9550\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.11317 to 0.13062, saving model to weight.hdf5\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 5/12\n",
            "2296/2296 [==============================] - 653s 284ms/step - loss: 0.0471 - accuracy: 0.9817 - val_loss: 0.1524 - val_accuracy: 0.9530\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.13062 to 0.15243, saving model to weight.hdf5\n",
            "Epoch 6/12\n",
            "2296/2296 [==============================] - 650s 283ms/step - loss: 0.0404 - accuracy: 0.9844 - val_loss: 0.1693 - val_accuracy: 0.9528\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.15243 to 0.16929, saving model to weight.hdf5\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 7/12\n",
            "2296/2296 [==============================] - 651s 283ms/step - loss: 0.0356 - accuracy: 0.9864 - val_loss: 0.1724 - val_accuracy: 0.9525\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.16929 to 0.17245, saving model to weight.hdf5\n",
            "Epoch 8/12\n",
            "2296/2296 [==============================] - 658s 286ms/step - loss: 0.0353 - accuracy: 0.9867 - val_loss: 0.1745 - val_accuracy: 0.9522\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.17245 to 0.17450, saving model to weight.hdf5\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 9/12\n",
            "2296/2296 [==============================] - 660s 287ms/step - loss: 0.0343 - accuracy: 0.9871 - val_loss: 0.1749 - val_accuracy: 0.9523\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.17450 to 0.17491, saving model to weight.hdf5\n",
            "Epoch 10/12\n",
            "2296/2296 [==============================] - 657s 286ms/step - loss: 0.0348 - accuracy: 0.9868 - val_loss: 0.1752 - val_accuracy: 0.9522\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.17491 to 0.17515, saving model to weight.hdf5\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "Epoch 11/12\n",
            "2296/2296 [==============================] - 654s 285ms/step - loss: 0.0345 - accuracy: 0.9868 - val_loss: 0.1753 - val_accuracy: 0.9522\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.17515 to 0.17531, saving model to weight.hdf5\n",
            "Epoch 12/12\n",
            "2296/2296 [==============================] - 652s 284ms/step - loss: 0.0344 - accuracy: 0.9869 - val_loss: 0.1756 - val_accuracy: 0.9523\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.17531 to 0.17559, saving model to weight.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKlZl7RxJZcW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "da7dce46-a8a6-47ef-8160-22c0b157b7ac"
      },
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy', color='green')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.plot(history.history['loss'], label='Train Loss', color='green')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe18b1d8090>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkLq4zpyJZfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5939a9b-3d7e-4085-b59b-da0bfd32484e"
      },
      "source": [
        "pred_val_y = model.predict([valid_x], batch_size=1024, verbose=1)\n",
        "\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {} is {}\".format(thresh, f1_score(valid_y, (pred_val_y > thresh).astype(int))))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128/128 [==============================] - 10s 73ms/step\n",
            "F1 score at threshold 0.1 is 0.5937973532680068\n",
            "F1 score at threshold 0.11 is 0.597843307609751\n",
            "F1 score at threshold 0.12 is 0.6009316770186336\n",
            "F1 score at threshold 0.13 is 0.6021156263091747\n",
            "F1 score at threshold 0.14 is 0.6038394415357765\n",
            "F1 score at threshold 0.15 is 0.6048868971404183\n",
            "F1 score at threshold 0.16 is 0.6049814406369358\n",
            "F1 score at threshold 0.17 is 0.6055871982641715\n",
            "F1 score at threshold 0.18 is 0.6063486860077583\n",
            "F1 score at threshold 0.19 is 0.6072451001981943\n",
            "F1 score at threshold 0.2 is 0.6073646850044365\n",
            "F1 score at threshold 0.21 is 0.6069373847958442\n",
            "F1 score at threshold 0.22 is 0.6071428571428571\n",
            "F1 score at threshold 0.23 is 0.6086069059363837\n",
            "F1 score at threshold 0.24 is 0.6083732603239791\n",
            "F1 score at threshold 0.25 is 0.608071645903898\n",
            "F1 score at threshold 0.26 is 0.6081932166175537\n",
            "F1 score at threshold 0.27 is 0.6090090090090089\n",
            "F1 score at threshold 0.28 is 0.6088276506305464\n",
            "F1 score at threshold 0.29 is 0.608072381176194\n",
            "F1 score at threshold 0.3 is 0.6079659614702754\n",
            "F1 score at threshold 0.31 is 0.6085923108919127\n",
            "F1 score at threshold 0.32 is 0.6087787399223649\n",
            "F1 score at threshold 0.33 is 0.6078243129725188\n",
            "F1 score at threshold 0.34 is 0.6079449408355468\n",
            "F1 score at threshold 0.35 is 0.6078098471986416\n",
            "F1 score at threshold 0.36 is 0.6067511576894955\n",
            "F1 score at threshold 0.37 is 0.6066356513222331\n",
            "F1 score at threshold 0.38 is 0.6065936769590355\n",
            "F1 score at threshold 0.39 is 0.6057834898665347\n",
            "F1 score at threshold 0.4 is 0.6039001366289901\n",
            "F1 score at threshold 0.41 is 0.6033547421587578\n",
            "F1 score at threshold 0.42 is 0.6030094043887148\n",
            "F1 score at threshold 0.43 is 0.6006804435483871\n",
            "F1 score at threshold 0.44 is 0.6003799873337556\n",
            "F1 score at threshold 0.45 is 0.5995673749840946\n",
            "F1 score at threshold 0.46 is 0.5981965850227026\n",
            "F1 score at threshold 0.47 is 0.5962181631077952\n",
            "F1 score at threshold 0.48 is 0.5944268442490463\n",
            "F1 score at threshold 0.49 is 0.5932666060054596\n",
            "F1 score at threshold 0.5 is 0.5930521091811414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzSpUd-_JZh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e158b1-beb4-4a3b-8c6c-68724acdebe8"
      },
      "source": [
        "test_y = model.predict([test_x], batch_size=1024, verbose=1) \n",
        "test_y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "367/367 [==============================] - 27s 73ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.7748876e-01],\n",
              "       [7.0391287e-08],\n",
              "       [1.2819999e-06],\n",
              "       ...,\n",
              "       [1.3032778e-06],\n",
              "       [4.5364931e-10],\n",
              "       [1.2749365e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeLbcIrxJZk-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4huS7OWKx9P1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY6weE0ELWgG"
      },
      "source": [
        "# Without Pretrained Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBG1NwA2Lag6"
      },
      "source": [
        "### Checking Null"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KQmts-PJZtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22e85b1-6946-4fbf-eccb-b364699ca284"
      },
      "source": [
        "# Checking null in both train and test\n",
        "train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "qid              0\n",
              "question_text    0\n",
              "target           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4fMlcQMJZws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd280b6e-af32-42a5-912e-b913054652c1"
      },
      "source": [
        "test.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "qid              0\n",
              "question_text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrzh3yGX69V2"
      },
      "source": [
        "test_x = test['question_text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm4035u7LhoY"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VloRRcLsJZzk"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e17hLufoJZ2b"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.split()\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    text = [w.translate(table) for w in text]\n",
        "    text = \" \".join(text)\n",
        "\n",
        "    # Remove link\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Remove non-alphabetic word\n",
        "    text = [word for word in text.split() if word.isalpha()]\n",
        "    text = \" \".join(text) \n",
        "\n",
        "    # Replace contractions with their longer forms \n",
        "    text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in text.split(\" \")])   \n",
        "\n",
        "    # Optionally, remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = [w for w in text.split() if not w in stop_words] \n",
        "    text = \" \".join(text) \n",
        "\n",
        "    # Stemming of the word \n",
        "    porter = PorterStemmer()\n",
        "    stemmed = [porter.stem(word) for word in text.split()] \n",
        "    text = \" \".join(stemmed) \n",
        "    \n",
        "    return text "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KybGEUpoJare"
      },
      "source": [
        "train['question_text'] = train['question_text'].apply(lambda x: clean_text(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwAl0aRK4XbI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0o4muolLrPI"
      },
      "source": [
        "# Dividing the Train into train and valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzZU0BB6JauW"
      },
      "source": [
        "train_df, valid_df = train_test_split(train, test_size=.2, \n",
        "                                      random_state=42, \n",
        "                                      stratify=train['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqS55AUWLwsn"
      },
      "source": [
        "# Tokenizing and Pad Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MboB7u9JaxT"
      },
      "source": [
        "embed_size = 300\n",
        "max_features = 50000\n",
        "maxlen = 100\n",
        "\n",
        "train_x = train_df['question_text'].values\n",
        "valid_x = valid_df['question_text'].values\n",
        "text_x = test['question_text'].values \n",
        "\n",
        "# Tokenizer \n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_x))\n",
        "train_x = tokenizer.texts_to_sequences(train_x)\n",
        "valid_x = tokenizer.texts_to_sequences(valid_x)\n",
        "test_x = tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "# Pad Sequence\n",
        "train_x = pad_sequences(train_x, maxlen=maxlen) \n",
        "valid_x = pad_sequences(valid_x, maxlen=maxlen)\n",
        "test_x = pad_sequences(test_x, maxlen=maxlen)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fnOT9vLJaz3"
      },
      "source": [
        "train_y = train_df['target'].values\n",
        "valid_y = valid_df['target'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhhBqzq3L3dJ"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNT8fYwY78z-"
      },
      "source": [
        "# ## some config values \n",
        "# embed_size = 300 \n",
        "# max_features = 50000 \n",
        "# maxlen = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N_h6PZEJa3B"
      },
      "source": [
        "# Building Model\n",
        "input = Input(shape=(maxlen,))\n",
        "x = Embedding(max_features, embed_size)(input)\n",
        "x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=input, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC8w-mU7Ja5t"
      },
      "source": [
        "# Compile Model\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZo3mpGIL8oW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29245b6-1239-428d-d445-b679e7ee2fc3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100, 128)          140544    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 15,142,625\n",
            "Trainable params: 15,142,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCH2RVlqMA6v"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCbCpN4FL8rR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324949c5-d282-4566-a3c1-803e402ee610"
      },
      "source": [
        "model.fit(train_x, train_y, \n",
        "          batch_size=512, \n",
        "          epochs=3, \n",
        "          validation_data=(valid_x, valid_y)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2041/2041 [==============================] - 619s 287ms/step - loss: 0.1598 - accuracy: 0.9445 - val_loss: 0.1155 - val_accuracy: 0.9541\n",
            "Epoch 2/3\n",
            "2041/2041 [==============================] - 579s 284ms/step - loss: 0.1066 - accuracy: 0.9579 - val_loss: 0.1153 - val_accuracy: 0.9543\n",
            "Epoch 3/3\n",
            "2041/2041 [==============================] - 583s 286ms/step - loss: 0.0932 - accuracy: 0.9630 - val_loss: 0.1196 - val_accuracy: 0.9547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2520b2e150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rko6noSTL8t4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f37609-bda9-4310-ce4b-9fe57080f9d0"
      },
      "source": [
        "# Now let us get the validation sample predictions and also get the best threshold for F1 score. \n",
        "valid_pred = model.predict([valid_x], batch_size=1024, verbose=1) \n",
        "\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 Score at threshold {} is {}\".format(thresh, f1_score(valid_y, (valid_pred>thresh).astype(int))))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256/256 [==============================] - 19s 73ms/step\n",
            "F1 Score at threshold 0.1 is 0.5576368273612912\n",
            "F1 Score at threshold 0.11 is 0.5644560517189707\n",
            "F1 Score at threshold 0.12 is 0.571816727655192\n",
            "F1 Score at threshold 0.13 is 0.5777767833169247\n",
            "F1 Score at threshold 0.14 is 0.5832781721485473\n",
            "F1 Score at threshold 0.15 is 0.5885008260232216\n",
            "F1 Score at threshold 0.16 is 0.5932163187855788\n",
            "F1 Score at threshold 0.17 is 0.5972570987058141\n",
            "F1 Score at threshold 0.18 is 0.600805066025232\n",
            "F1 Score at threshold 0.19 is 0.6045676672982946\n",
            "F1 Score at threshold 0.2 is 0.607327455153542\n",
            "F1 Score at threshold 0.21 is 0.6105333436047556\n",
            "F1 Score at threshold 0.22 is 0.6120397854501901\n",
            "F1 Score at threshold 0.23 is 0.6136189747513389\n",
            "F1 Score at threshold 0.24 is 0.6155942710560067\n",
            "F1 Score at threshold 0.25 is 0.6164250162302531\n",
            "F1 Score at threshold 0.26 is 0.6179707605541258\n",
            "F1 Score at threshold 0.27 is 0.6185241589367299\n",
            "F1 Score at threshold 0.28 is 0.6185474609976752\n",
            "F1 Score at threshold 0.29 is 0.618049845473362\n",
            "F1 Score at threshold 0.3 is 0.6189589480619934\n",
            "F1 Score at threshold 0.31 is 0.6190117592538956\n",
            "F1 Score at threshold 0.32 is 0.6185723901782317\n",
            "F1 Score at threshold 0.33 is 0.617894830185333\n",
            "F1 Score at threshold 0.34 is 0.6175073918107697\n",
            "F1 Score at threshold 0.35 is 0.6170180677465087\n",
            "F1 Score at threshold 0.36 is 0.6159047299972588\n",
            "F1 Score at threshold 0.37 is 0.6144003936886784\n",
            "F1 Score at threshold 0.38 is 0.6137069715421897\n",
            "F1 Score at threshold 0.39 is 0.6125621499150355\n",
            "F1 Score at threshold 0.4 is 0.6104507024346831\n",
            "F1 Score at threshold 0.41 is 0.6076347641827463\n",
            "F1 Score at threshold 0.42 is 0.6051504929942917\n",
            "F1 Score at threshold 0.43 is 0.6037636876270409\n",
            "F1 Score at threshold 0.44 is 0.5999072171780767\n",
            "F1 Score at threshold 0.45 is 0.5977926421404682\n",
            "F1 Score at threshold 0.46 is 0.5951720873622287\n",
            "F1 Score at threshold 0.47 is 0.591854893908282\n",
            "F1 Score at threshold 0.48 is 0.5878036962691215\n",
            "F1 Score at threshold 0.49 is 0.5852652190636036\n",
            "F1 Score at threshold 0.5 is 0.5812703352666573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY0SDDzRMMF5"
      },
      "source": [
        "# Predicting with test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcw3B5_jL8wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988ec529-e849-4bd4-f225-0ea01d8bb068"
      },
      "source": [
        "test_y = model.predict([test_x], batch_size=1024, verbose=1)\n",
        "test_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "367/367 [==============================] - 26s 72ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.0836301e-02],\n",
              "       [7.5832992e-05],\n",
              "       [2.5001622e-03],\n",
              "       ...,\n",
              "       [2.7769132e-04],\n",
              "       [8.1535050e-04],\n",
              "       [1.5284970e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0xTvwGV1eE_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}