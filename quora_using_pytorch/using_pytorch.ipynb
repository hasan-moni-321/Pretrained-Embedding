{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "pF6HiBU44x8i",
        "outputId": "63b5a77c-5c2f-40ae-bcec-2349c8e99b2c"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload() #upload kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-58da78b8-88f5-46b2-8253-ebe98916e33b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-58da78b8-88f5-46b2-8253-ebe98916e33b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"hasanmoni\",\"key\":\"9142c075d789cc76a7a383e1a7811a5e\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuhpRFKB4x4A",
        "outputId": "24eb772f-882b-42bb-ca75-270eba29b5b1"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycvyWkjD5EYV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boTwZWVo5Eba"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "import os, re, random, time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdP49R3m1RbU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH65jTzS0-vA"
      },
      "source": [
        "def seed_torch(seed=1029):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmkaIdbz8ZHJ"
      },
      "source": [
        "# Reading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-umEAtc1CuA"
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/Colab Folder/Quora Insincere Question/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/Colab Folder/Quora Insincere Question/test.csv\")\n",
        "sub = pd.read_csv('/content/drive/MyDrive/Colab Folder/Quora Insincere Question/sample_submission.csv')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd99VO0e8cjK"
      },
      "source": [
        "# Preview of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "vA3qRnsvord8",
        "outputId": "3cb198ab-9aea-4472-c29e-c0194da2521a"
      },
      "source": [
        "print(\"Shape of train is {}\".format(train.shape))\n",
        "train.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train is (1306122, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... target\n",
              "0  00002165364db923c7e6  ...      0\n",
              "1  000032939017120e6e44  ...      0\n",
              "2  0000412ca6e4628ce2cf  ...      0\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "uUU5smtFo6av",
        "outputId": "01483e92-0b68-4508-deef-1e05d1647397"
      },
      "source": [
        "print(\"Shape of test is {}\".format(test.shape))\n",
        "test.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of test is (375806, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>Why do so many women become so rude and arroga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>When should I apply for RV college of engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>What is it really like to be a nurse practitio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid                                      question_text\n",
              "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
              "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
              "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avhx-MzR1Czv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1ba921-da9b-43b0-e9aa-3604f70df916"
      },
      "source": [
        "train[\"target\"].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1225312\n",
              "1      80810\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "605UEwgx1C2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "edc7b090-be7b-4e85-8455-b66328561cd8"
      },
      "source": [
        "train[\"target\"].value_counts().plot(kind='bar')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f78e379eb50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ycqliSzLgdP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnrkq7Di34Ag"
      },
      "source": [
        "# Some Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btzVFzdt1C5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072ce8f7-e686-4ef3-e129-c63aac95a347"
      },
      "source": [
        "# Number of average words in both train and test dataset \n",
        "print('Average word length of questions in train is {0:.0f}.'.format(np.mean(train['question_text'].apply(lambda x: len(x.split())))))\n",
        "print('Average word length of questions in test is {0:.0f}.'.format(np.mean(test['question_text'].apply(lambda x: len(x.split())))))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average word length of questions in train is 13.\n",
            "Average word length of questions in test is 13.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2A0eGeK1C7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3761839-110f-4859-d9fd-5edf10f81c8d"
      },
      "source": [
        "# Number of max words in both train and test dataset \n",
        "print('Max word length of questions in train is {0:.0f}.'.format(np.max(train['question_text'].apply(lambda x: len(x.split())))))\n",
        "print('Max word length of questions in test is {0:.0f}.'.format(np.max(test['question_text'].apply(lambda x: len(x.split())))))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max word length of questions in train is 134.\n",
            "Max word length of questions in test is 87.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHVNgOTm-jmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664d53c5-106d-4a14-853a-1eae7ddf691f"
      },
      "source": [
        "# Number of average character in both train and test dataset \n",
        "print('Average character length of questions in train is {0:.0f}.'.format(np.mean(train['question_text'].apply(lambda x: len(x)))))\n",
        "print('Average character length of questions in test is {0:.0f}.'.format(np.mean(test['question_text'].apply(lambda x: len(x)))))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average character length of questions in train is 71.\n",
            "Average character length of questions in test is 71.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JaQNjyx30Qn"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvpqITcg8TTR"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDDikQzK-jp6"
      },
      "source": [
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        x = x.replace(punct, f' {punct} ')\n",
        "    return x\n",
        "\n",
        "def clean_numbers(x):\n",
        "    x = re.sub('[0-9]{5,}', '#####', x)\n",
        "    x = re.sub('[0-9]{4}', '####', x)\n",
        "    x = re.sub('[0-9]{3}', '###', x)\n",
        "    x = re.sub('[0-9]{2}', '##', x)\n",
        "    return x\n",
        "\n",
        "mispell_dict = {\"aren't\" : \"are not\",\n",
        "\"can't\" : \"cannot\",\n",
        "\"couldn't\" : \"could not\",\n",
        "\"didn't\" : \"did not\",\n",
        "\"doesn't\" : \"does not\",\n",
        "\"don't\" : \"do not\",\n",
        "\"hadn't\" : \"had not\",\n",
        "\"hasn't\" : \"has not\",\n",
        "\"haven't\" : \"have not\",\n",
        "\"he'd\" : \"he would\",\n",
        "\"he'll\" : \"he will\",\n",
        "\"he's\" : \"he is\",\n",
        "\"i'd\" : \"I would\",\n",
        "\"i'd\" : \"I had\",\n",
        "\"i'll\" : \"I will\",\n",
        "\"i'm\" : \"I am\",\n",
        "\"isn't\" : \"is not\",\n",
        "\"it's\" : \"it is\",\n",
        "\"it'll\":\"it will\",\n",
        "\"i've\" : \"I have\",\n",
        "\"let's\" : \"let us\",\n",
        "\"mightn't\" : \"might not\",\n",
        "\"mustn't\" : \"must not\",\n",
        "\"shan't\" : \"shall not\",\n",
        "\"she'd\" : \"she would\",\n",
        "\"she'll\" : \"she will\",\n",
        "\"she's\" : \"she is\",\n",
        "\"shouldn't\" : \"should not\",\n",
        "\"that's\" : \"that is\",\n",
        "\"there's\" : \"there is\",\n",
        "\"they'd\" : \"they would\",\n",
        "\"they'll\" : \"they will\",\n",
        "\"they're\" : \"they are\",\n",
        "\"they've\" : \"they have\",\n",
        "\"we'd\" : \"we would\",\n",
        "\"we're\" : \"we are\",\n",
        "\"weren't\" : \"were not\",\n",
        "\"we've\" : \"we have\",\n",
        "\"what'll\" : \"what will\",\n",
        "\"what're\" : \"what are\",\n",
        "\"what's\" : \"what is\",\n",
        "\"what've\" : \"what have\",\n",
        "\"where's\" : \"where is\",\n",
        "\"who'd\" : \"who would\",\n",
        "\"who'll\" : \"who will\",\n",
        "\"who're\" : \"who are\",\n",
        "\"who's\" : \"who is\",\n",
        "\"who've\" : \"who have\",\n",
        "\"won't\" : \"will not\",\n",
        "\"wouldn't\" : \"would not\",\n",
        "\"you'd\" : \"you would\",\n",
        "\"you'll\" : \"you will\",\n",
        "\"you're\" : \"you are\",\n",
        "\"you've\" : \"you have\",\n",
        "\"'re\": \" are\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'll\":\" will\",\n",
        "\"didn't\": \"did not\",\n",
        "\"tryin'\":\"trying\"}\n",
        "\n",
        "def _get_mispell(mispell_dict):\n",
        "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
        "    return mispell_dict, mispell_re\n",
        "\n",
        "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
        "def replace_typical_misspell(text):\n",
        "    def replace(match):\n",
        "        return mispellings[match.group(0)]\n",
        "    return mispellings_re.sub(replace, text)\n",
        "\n",
        "# Clean the text\n",
        "train[\"question_text\"] = train[\"question_text\"].apply(lambda x: clean_text(x.lower()))\n",
        "test[\"question_text\"] = test[\"question_text\"].apply(lambda x: clean_text(x.lower()))\n",
        "\n",
        "# Clean numbers\n",
        "train[\"question_text\"] = train[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
        "test[\"question_text\"] = test[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
        "\n",
        "# Clean speelings\n",
        "train[\"question_text\"] = train[\"question_text\"].apply(lambda x: replace_typical_misspell(x))\n",
        "test[\"question_text\"] = test[\"question_text\"].apply(lambda x: replace_typical_misspell(x))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2g0roUK8sRZ"
      },
      "source": [
        "# Tokenization and Pad Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bou4ywQR-jsU"
      },
      "source": [
        "max_features = 120000\n",
        "tk = Tokenizer(lower = True, filters='', num_words=max_features)\n",
        "full_text = list(train['question_text'].values) + list(test['question_text'].values)\n",
        "tk.fit_on_texts(full_text)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWdR5ufb-jua"
      },
      "source": [
        "train_tokenized = tk.texts_to_sequences(train['question_text'].fillna('missing'))\n",
        "test_tokenized = tk.texts_to_sequences(test['question_text'].fillna('missing'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_phXyhXh-1lS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "2b5f5347-bd94-4c6c-df24-3de6b774588b"
      },
      "source": [
        "train['question_text'].apply(lambda x: len(x.split())).plot(kind='hist');\n",
        "plt.yscale('log');\n",
        "plt.title('Distribution of question text length in characters');\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0njvsQlk-1oi"
      },
      "source": [
        "max_len = 72\n",
        "maxlen = 72\n",
        "X_train = pad_sequences(train_tokenized, maxlen = max_len)\n",
        "X_test = pad_sequences(test_tokenized, maxlen = max_len)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOSHQQGE-1si"
      },
      "source": [
        "y_train = train['target'].values"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGrbF5MC-7s5"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyvoqcvb2l2L"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "splits = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=10).split(X_train, y_train))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYmUSEwXAs5j"
      },
      "source": [
        "# Combination of Two Pretrained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX3KuqK1-7vi"
      },
      "source": [
        "embed_size = 300\n",
        "embedding_path = \"/content/drive/MyDrive/Colab Folder/Quora Insincere Question/glove.840B.300d.txt\"\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore'))\n",
        "# all_embs = np.stack(embedding_index.values())\n",
        "# emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "emb_mean,emb_std = -0.005838499, 0.48782197\n",
        "word_index = tk.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC1C7mIa-7x3"
      },
      "source": [
        "embedding_path = \"/content/drive/MyDrive/Colab Folder/Quora Insincere Question/paragram_300_sl999.txt\"\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore') if len(o)>100)\n",
        "# all_embs = np.stack(embedding_index.values())\n",
        "# emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "emb_mean,emb_std = -0.0053247833, 0.49346462\n",
        "embedding_matrix1 = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix1[i] = embedding_vector\n",
        "    "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBmSH_WE-70j"
      },
      "source": [
        "embedding_matrix = np.mean([embedding_matrix, embedding_matrix1], axis=0)\n",
        "del embedding_matrix1\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyX8RfZM_IEw"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzZJv8fJ-73V"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.bias = bias\n",
        "        self.feature_dim = feature_dim\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        \n",
        "        weight = torch.zeros(feature_dim, 1)\n",
        "        nn.init.xavier_uniform_(weight)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        \n",
        "        if bias:\n",
        "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
        "        \n",
        "    def forward(self, x, mask=None):\n",
        "        feature_dim = self.feature_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = torch.mm(\n",
        "            x.contiguous().view(-1, feature_dim), \n",
        "            self.weight\n",
        "        ).view(-1, step_dim)\n",
        "        \n",
        "        if self.bias:\n",
        "            eij = eij + self.b\n",
        "            \n",
        "        eij = torch.tanh(eij)\n",
        "        a = torch.exp(eij)\n",
        "        \n",
        "        if mask is not None:\n",
        "            a = a * mask\n",
        "\n",
        "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
        "\n",
        "        weighted_input = x * torch.unsqueeze(a, -1)\n",
        "        return torch.sum(weighted_input, 1)\n",
        "    \n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        \n",
        "        hidden_size = 128\n",
        "        \n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        \n",
        "        self.embedding_dropout = nn.Dropout2d(0.1)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.gru = nn.GRU(hidden_size*2, hidden_size, bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.lstm_attention = Attention(hidden_size*2, maxlen)\n",
        "        self.gru_attention = Attention(hidden_size*2, maxlen)\n",
        "        \n",
        "        self.linear = nn.Linear(1024, 16)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.out = nn.Linear(16, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))\n",
        "        \n",
        "        h_lstm, _ = self.lstm(h_embedding)\n",
        "        h_gru, _ = self.gru(h_lstm)\n",
        "        \n",
        "        h_lstm_atten = self.lstm_attention(h_lstm)\n",
        "        h_gru_atten = self.gru_attention(h_gru)\n",
        "        \n",
        "        avg_pool = torch.mean(h_gru, 1)\n",
        "        max_pool, _ = torch.max(h_gru, 1)\n",
        "        \n",
        "        conc = torch.cat((h_lstm_atten, h_gru_atten, avg_pool, max_pool), 1)\n",
        "        conc = self.relu(self.linear(conc))\n",
        "        conc = self.dropout(conc)\n",
        "        out = self.out(conc)\n",
        "        \n",
        "        return out\n",
        "        "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAbIvE0v_MaZ"
      },
      "source": [
        "m = NeuralNet()\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTmB4IiPA8-p"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQV3zAzCAoPH"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sjYqj6a_Mdg"
      },
      "source": [
        "def train_model(model, x_train, y_train, x_val, y_val, validate=True):\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    # scheduler = CosineAnnealingLR(optimizer, T_max=5)\n",
        "    # scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "    \n",
        "    train = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "    valid = torch.utils.data.TensorDataset(x_val, y_val)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean').cuda()\n",
        "    best_score = -np.inf\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "        \n",
        "        for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
        "            y_pred = model(x_batch)\n",
        "            \n",
        "            \n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "            \n",
        "        model.eval()\n",
        "        \n",
        "        valid_preds = np.zeros((x_val_fold.size(0)))\n",
        "        \n",
        "        if validate:\n",
        "            avg_val_loss = 0.\n",
        "            for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "                y_pred = model(x_batch).detach()\n",
        "\n",
        "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "                valid_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
        "            search_result = threshold_search(y_val.cpu().numpy(), valid_preds)\n",
        "\n",
        "            val_f1, val_threshold = search_result['f1'], search_result['threshold']\n",
        "            elapsed_time = time.time() - start_time\n",
        "            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t val_f1={:.4f} best_t={:.2f} \\t time={:.2f}s'.format(\n",
        "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_f1, val_threshold, elapsed_time))\n",
        "        else:\n",
        "            elapsed_time = time.time() - start_time\n",
        "            print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
        "                epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
        "    \n",
        "    valid_preds = np.zeros((x_val_fold.size(0)))\n",
        "    \n",
        "    avg_val_loss = 0.\n",
        "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "        y_pred = model(x_batch).detach()\n",
        "\n",
        "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "        valid_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
        "\n",
        "    print('Validation loss: ', avg_val_loss)\n",
        "\n",
        "    test_preds = np.zeros((len(test_loader.dataset)))\n",
        "    \n",
        "    for i, (x_batch,) in enumerate(test_loader):\n",
        "        y_pred = model(x_batch).detach()\n",
        "\n",
        "        test_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
        "    # scheduler.step()\n",
        "    \n",
        "    return valid_preds, test_preds#, test_preds_local\n",
        "    "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3imRZ5_Mgy"
      },
      "source": [
        "x_test_cuda = torch.tensor(X_test, dtype=torch.long).cuda()\n",
        "test = torch.utils.data.TensorDataset(x_test_cuda)\n",
        "batch_size = 512\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJeiECHv_VeI"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj5jj7yp_iH7"
      },
      "source": [
        "seed=1029\n",
        "\n",
        "def threshold_search(y_true, y_proba):\n",
        "    best_threshold = 0\n",
        "    best_score = 0\n",
        "    for threshold in tqdm([i * 0.01 for i in range(100)], disable=True):\n",
        "        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n",
        "        if score > best_score:\n",
        "            best_threshold = threshold\n",
        "            best_score = score\n",
        "    search_result = {'threshold': best_threshold, 'f1': best_score}\n",
        "    return search_result\n",
        "\n",
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwIRafp-75jr"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14skTZUy_Vgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1d0f82-a2ea-4b6c-a794-2911c5461e7d"
      },
      "source": [
        "train_preds = np.zeros(len(train))\n",
        "test_preds = np.zeros((len(test), len(splits)))\n",
        "n_epochs = 5\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "for i, (train_idx, valid_idx) in enumerate(splits):    \n",
        "    x_train_fold = torch.tensor(X_train[train_idx], dtype=torch.long).cuda()\n",
        "    y_train_fold = torch.tensor(y_train[train_idx, np.newaxis], dtype=torch.float32).cuda()\n",
        "    x_val_fold = torch.tensor(X_train[valid_idx], dtype=torch.long).cuda()\n",
        "    y_val_fold = torch.tensor(y_train[valid_idx, np.newaxis], dtype=torch.float32).cuda()\n",
        "    \n",
        "    train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
        "    valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    print(f'Fold {i + 1}')\n",
        "    \n",
        "    seed_everything(seed + i)\n",
        "    model = NeuralNet()\n",
        "    model.cuda()\n",
        "\n",
        "    valid_preds_fold, test_preds_fold = train_model(model,\n",
        "                                                    x_train_fold, \n",
        "                                                    y_train_fold, \n",
        "                                                    x_val_fold, \n",
        "                                                    y_val_fold, validate=False)\n",
        "\n",
        "    train_preds[valid_idx] = valid_preds_fold\n",
        "    test_preds[:, i] = test_preds_fold\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Epoch 1/5 \t loss=0.1302 \t time=142.39s\n",
            "Epoch 2/5 \t loss=0.1132 \t time=147.99s\n",
            "Epoch 3/5 \t loss=0.1069 \t time=148.70s\n",
            "Epoch 4/5 \t loss=0.0999 \t time=147.51s\n",
            "Epoch 5/5 \t loss=0.0922 \t time=148.77s\n",
            "Validation loss:  0.10214872136828862\n",
            "Fold 2\n",
            "Epoch 1/5 \t loss=0.1295 \t time=148.00s\n",
            "Epoch 2/5 \t loss=0.1136 \t time=148.99s\n",
            "Epoch 3/5 \t loss=0.1064 \t time=148.20s\n",
            "Epoch 4/5 \t loss=0.0996 \t time=148.60s\n",
            "Epoch 5/5 \t loss=0.0918 \t time=147.94s\n",
            "Validation loss:  0.09860430843544228\n",
            "Fold 3\n",
            "Epoch 1/5 \t loss=0.1306 \t time=148.00s\n",
            "Epoch 2/5 \t loss=0.1141 \t time=147.84s\n",
            "Epoch 3/5 \t loss=0.1076 \t time=148.37s\n",
            "Epoch 4/5 \t loss=0.1009 \t time=148.66s\n",
            "Epoch 5/5 \t loss=0.0936 \t time=148.57s\n",
            "Validation loss:  0.0994655355565881\n",
            "Fold 4\n",
            "Epoch 1/5 \t loss=0.1289 \t time=148.67s\n",
            "Epoch 2/5 \t loss=0.1136 \t time=149.11s\n",
            "Epoch 3/5 \t loss=0.1070 \t time=149.09s\n",
            "Epoch 4/5 \t loss=0.1002 \t time=149.28s\n",
            "Epoch 5/5 \t loss=0.0921 \t time=148.92s\n",
            "Validation loss:  0.1023168780353376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zIxzMYE_VjY"
      },
      "source": [
        "search_result = threshold_search(y_train, train_preds)\n",
        "sub['prediction'] = test_preds.mean(1) > search_result['threshold']\n",
        "sub.to_csv(\"submission.csv\", index=False)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iQLd6xw3GIw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f895ff22-106d-4e33-ba1a-354f0f61b7ef"
      },
      "source": [
        "sub = pd.read_csv(\"submission.csv\")\n",
        "sub.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  prediction\n",
              "0  0000163e3ea7c7a74cd7        True\n",
              "1  00002bd4fb5d505b9161       False\n",
              "2  00007756b4a147d2b0b3       False\n",
              "3  000086e4b7e1c7146103       False\n",
              "4  0000c4c3fbe8785a3090       False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cdLkaPZV_Ed"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}