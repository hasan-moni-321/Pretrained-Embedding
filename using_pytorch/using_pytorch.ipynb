{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "using pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycvyWkjD5EYV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boTwZWVo5Eba"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "import os, re, random, time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdP49R3m1RbU"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH65jTzS0-vA"
      },
      "source": [
        "def seed_torch(seed=1029):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmkaIdbz8ZHJ"
      },
      "source": [
        "# Reading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-umEAtc1CuA"
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/Colab Folder/Quora Insincere Question/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/Colab Folder/Quora Insincere Question/test.csv\")\n",
        "sub = pd.read_csv('/content/drive/MyDrive/Colab Folder/Quora Insincere Question/sample_submission.csv')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd99VO0e8cjK"
      },
      "source": [
        "# Preview of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "vA3qRnsvord8",
        "outputId": "a2f48a2c-6912-4d34-ae32-a54fc0c26857"
      },
      "source": [
        "print(\"Shape of train is {}\".format(train.shape))\n",
        "train.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train is (1306122, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... target\n",
              "0  00002165364db923c7e6  ...      0\n",
              "1  000032939017120e6e44  ...      0\n",
              "2  0000412ca6e4628ce2cf  ...      0\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "uUU5smtFo6av",
        "outputId": "d0f1dc0a-da1c-4489-aed9-e1805893720e"
      },
      "source": [
        "print(\"Shape of test is {}\".format(test.shape))\n",
        "test.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of test is (375806, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>Why do so many women become so rude and arroga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>When should I apply for RV college of engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>What is it really like to be a nurse practitio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid                                      question_text\n",
              "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
              "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
              "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avhx-MzR1Czv",
        "outputId": "e0bf6774-72ef-4cb8-d5b5-00d468480ac1"
      },
      "source": [
        "train[\"target\"].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1225312\n",
              "1      80810\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "605UEwgx1C2d",
        "outputId": "87d04c8a-4bab-4d24-a12a-4081afc85ff8"
      },
      "source": [
        "train[\"target\"].value_counts().plot(kind='bar')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff08f50cd50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ycqliSzLgdP"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnrkq7Di34Ag"
      },
      "source": [
        "# Some Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btzVFzdt1C5J",
        "outputId": "fb56b394-5884-4fbf-f6a5-45b8dbbe7cae"
      },
      "source": [
        "# Number of average words in both train and test dataset \n",
        "print('Average word in train is {0:.0f}.'.format(np.mean(train['question_text'].apply(lambda x: len(x.split())))))\n",
        "print('Average word in test is {0:.0f}.'.format(np.mean(test['question_text'].apply(lambda x: len(x.split())))))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average word in train is 13.\n",
            "Average word in test is 13.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2A0eGeK1C7i",
        "outputId": "ab222f29-0b0f-4c99-92c0-3ef06cd3e37b"
      },
      "source": [
        "# Number of max words in both train and test dataset \n",
        "print('Maximum word in train is {0:.0f}.'.format(np.max(train['question_text'].apply(lambda x: len(x.split())))))\n",
        "print('Maximum word in test is {0:.0f}.'.format(np.max(test['question_text'].apply(lambda x: len(x.split())))))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum word in train is 134.\n",
            "Maximum word in test is 87.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHVNgOTm-jmz",
        "outputId": "e217a10c-b557-426d-a850-565553e0ed36"
      },
      "source": [
        "# Number of average character in both train and test dataset \n",
        "print('Minimum word in train is {0:.0f}.'.format(np.min(train['question_text'].apply(lambda x: len(x)))))\n",
        "print('Minimum word in test is {0:.0f}.'.format(np.min(test['question_text'].apply(lambda x: len(x)))))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum word in train is 1.\n",
            "Minimum word in test is 6.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JaQNjyx30Qn"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvpqITcg8TTR"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDDikQzK-jp6"
      },
      "source": [
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        x = x.replace(punct, f' {punct} ')\n",
        "    return x\n",
        "\n",
        "def clean_numbers(x):\n",
        "    x = re.sub('[0-9]{5,}', '#####', x)\n",
        "    x = re.sub('[0-9]{4}', '####', x)\n",
        "    x = re.sub('[0-9]{3}', '###', x)\n",
        "    x = re.sub('[0-9]{2}', '##', x)\n",
        "    return x\n",
        "\n",
        "mispell_dict = {\"aren't\" : \"are not\",\n",
        "\"can't\" : \"cannot\",\n",
        "\"couldn't\" : \"could not\",\n",
        "\"didn't\" : \"did not\",\n",
        "\"doesn't\" : \"does not\",\n",
        "\"don't\" : \"do not\",\n",
        "\"hadn't\" : \"had not\",\n",
        "\"hasn't\" : \"has not\",\n",
        "\"haven't\" : \"have not\",\n",
        "\"he'd\" : \"he would\",\n",
        "\"he'll\" : \"he will\",\n",
        "\"he's\" : \"he is\",\n",
        "\"i'd\" : \"I would\",\n",
        "\"i'd\" : \"I had\",\n",
        "\"i'll\" : \"I will\",\n",
        "\"i'm\" : \"I am\",\n",
        "\"isn't\" : \"is not\",\n",
        "\"it's\" : \"it is\",\n",
        "\"it'll\":\"it will\",\n",
        "\"i've\" : \"I have\",\n",
        "\"let's\" : \"let us\",\n",
        "\"mightn't\" : \"might not\",\n",
        "\"mustn't\" : \"must not\",\n",
        "\"shan't\" : \"shall not\",\n",
        "\"she'd\" : \"she would\",\n",
        "\"she'll\" : \"she will\",\n",
        "\"she's\" : \"she is\",\n",
        "\"shouldn't\" : \"should not\",\n",
        "\"that's\" : \"that is\",\n",
        "\"there's\" : \"there is\",\n",
        "\"they'd\" : \"they would\",\n",
        "\"they'll\" : \"they will\",\n",
        "\"they're\" : \"they are\",\n",
        "\"they've\" : \"they have\",\n",
        "\"we'd\" : \"we would\",\n",
        "\"we're\" : \"we are\",\n",
        "\"weren't\" : \"were not\",\n",
        "\"we've\" : \"we have\",\n",
        "\"what'll\" : \"what will\",\n",
        "\"what're\" : \"what are\",\n",
        "\"what's\" : \"what is\",\n",
        "\"what've\" : \"what have\",\n",
        "\"where's\" : \"where is\",\n",
        "\"who'd\" : \"who would\",\n",
        "\"who'll\" : \"who will\",\n",
        "\"who're\" : \"who are\",\n",
        "\"who's\" : \"who is\",\n",
        "\"who've\" : \"who have\",\n",
        "\"won't\" : \"will not\",\n",
        "\"wouldn't\" : \"would not\",\n",
        "\"you'd\" : \"you would\",\n",
        "\"you'll\" : \"you will\",\n",
        "\"you're\" : \"you are\",\n",
        "\"you've\" : \"you have\",\n",
        "\"'re\": \" are\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'll\":\" will\",\n",
        "\"didn't\": \"did not\",\n",
        "\"tryin'\":\"trying\"}\n",
        "\n",
        "def _get_mispell(mispell_dict):\n",
        "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
        "    return mispell_dict, mispell_re\n",
        "\n",
        "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
        "def replace_typical_misspell(text):\n",
        "    def replace(match):\n",
        "        return mispellings[match.group(0)]\n",
        "    return mispellings_re.sub(replace, text)\n",
        "\n",
        "# Clean the text\n",
        "train[\"question_text\"] = train[\"question_text\"].apply(lambda x: clean_text(x.lower()))\n",
        "test[\"question_text\"] = test[\"question_text\"].apply(lambda x: clean_text(x.lower()))\n",
        "\n",
        "# Clean numbers\n",
        "train[\"question_text\"] = train[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
        "test[\"question_text\"] = test[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
        "\n",
        "# Clean speelings\n",
        "train[\"question_text\"] = train[\"question_text\"].apply(lambda x: replace_typical_misspell(x))\n",
        "test[\"question_text\"] = test[\"question_text\"].apply(lambda x: replace_typical_misspell(x))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1d2aSOTmDZD",
        "outputId": "3cc3e801-911b-4825-9bc1-cd550244be50"
      },
      "source": [
        "# After cleaning the average words \n",
        "print('After cleaning average word in train is {0:.0f}.'.format(np.mean(train['question_text'].apply(lambda x: len(x.split())))))\n",
        "print('After cleaning average word in test is {0:.0f}.'.format(np.mean(test['question_text'].apply(lambda x: len(x.split())))))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After cleaning average word in train is 15.\n",
            "After cleaning average word in test is 15.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFyDkGMNqCHM",
        "outputId": "d8ef85e2-d8f9-4aa9-e59a-f04c0d7468fc"
      },
      "source": [
        "# Minimum words after cleaning of the train and test \n",
        "print('Minimum word in train is {0:.0f}.'.format(np.min(train['question_text'].apply(lambda x: len(x)))))\n",
        "print('Minimum word in test is {0:.0f}.'.format(np.min(test['question_text'].apply(lambda x: len(x)))))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum word in train is 1.\n",
            "Minimum word in test is 7.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hUpQLKNqdgg",
        "outputId": "264a0411-b889-4a92-85e1-7addf6bc1ca6"
      },
      "source": [
        "# dropping rows where have less than 2 word\n",
        "train = train[train['question_text'].apply(lambda x: len(x.split()) > 2 ) ].reset_index(drop=True) \n",
        "print(\"Shape of train is {}\".format(train.shape)) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train is (1306098, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2g0roUK8sRZ"
      },
      "source": [
        "# Tokenization and Pad Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bou4ywQR-jsU"
      },
      "source": [
        "max_features = 120000\n",
        "tk = Tokenizer(lower = True, filters='', num_words=max_features)\n",
        "full_text = list(train['question_text'].values) + list(test['question_text'].values)\n",
        "tk.fit_on_texts(full_text)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWdR5ufb-jua"
      },
      "source": [
        "train_tokenized = tk.texts_to_sequences(train['question_text'].fillna('missing'))\n",
        "test_tokenized = tk.texts_to_sequences(test['question_text'].fillna('missing'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "_phXyhXh-1lS",
        "outputId": "4d9c912a-2eeb-4b06-adb0-a19983f5d0b9"
      },
      "source": [
        "train['question_text'].apply(lambda x: len(x.split())).plot(kind='hist');\n",
        "plt.yscale('log');\n",
        "plt.title('Distribution of question text length in characters');\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0njvsQlk-1oi"
      },
      "source": [
        "max_len = 72\n",
        "X_train = pad_sequences(train_tokenized, maxlen = max_len)\n",
        "X_test = pad_sequences(test_tokenized, maxlen = max_len)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOSHQQGE-1si"
      },
      "source": [
        "y_train = train['target'].values"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGrbF5MC-7s5"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyvoqcvb2l2L"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "splits = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=10).split(X_train, y_train))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYmUSEwXAs5j"
      },
      "source": [
        "# Combination of Two Pretrained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX3KuqK1-7vi"
      },
      "source": [
        "embed_size = 300\n",
        "embedding_path = \"/content/drive/MyDrive/Colab Folder/Quora Insincere Question/glove.840B.300d.txt\"\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore'))\n",
        "# all_embs = np.stack(embedding_index.values())\n",
        "# emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "emb_mean,emb_std = -0.005838499, 0.48782197\n",
        "word_index = tk.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC1C7mIa-7x3"
      },
      "source": [
        "embedding_path = \"/content/drive/MyDrive/Colab Folder/Quora Insincere Question/paragram_300_sl999.txt\"\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embedding_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_path, encoding='utf-8', errors='ignore') if len(o)>100)\n",
        "# all_embs = np.stack(embedding_index.values())\n",
        "# emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "emb_mean,emb_std = -0.0053247833, 0.49346462\n",
        "embedding_matrix1 = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix1[i] = embedding_vector\n",
        "    "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBmSH_WE-70j"
      },
      "source": [
        "embedding_matrix = np.mean([embedding_matrix, embedding_matrix1], axis=0)\n",
        "del embedding_matrix1\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyX8RfZM_IEw"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzZJv8fJ-73V"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.bias = bias\n",
        "        self.feature_dim = feature_dim\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        \n",
        "        weight = torch.zeros(feature_dim, 1)\n",
        "        nn.init.xavier_uniform_(weight)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        \n",
        "        if bias:\n",
        "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
        "        \n",
        "    def forward(self, x, mask=None):\n",
        "        feature_dim = self.feature_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = torch.mm(\n",
        "            x.contiguous().view(-1, feature_dim), \n",
        "            self.weight\n",
        "        ).view(-1, step_dim)\n",
        "        \n",
        "        if self.bias:\n",
        "            eij = eij + self.b\n",
        "            \n",
        "        eij = torch.tanh(eij)\n",
        "        a = torch.exp(eij)\n",
        "        \n",
        "        if mask is not None:\n",
        "            a = a * mask\n",
        "\n",
        "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
        "\n",
        "        weighted_input = x * torch.unsqueeze(a, -1)\n",
        "        return torch.sum(weighted_input, 1)\n",
        "    \n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        \n",
        "        hidden_size = 128\n",
        "        \n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        \n",
        "        self.embedding_dropout = nn.Dropout2d(0.1)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.gru = nn.GRU(hidden_size*2, hidden_size, bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.lstm_attention = Attention(hidden_size*2, maxlen)\n",
        "        self.gru_attention = Attention(hidden_size*2, maxlen)\n",
        "        \n",
        "        self.linear = nn.Linear(1024, 16)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.out = nn.Linear(16, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))\n",
        "        \n",
        "        h_lstm, _ = self.lstm(h_embedding)\n",
        "        h_gru, _ = self.gru(h_lstm)\n",
        "        \n",
        "        h_lstm_atten = self.lstm_attention(h_lstm)\n",
        "        h_gru_atten = self.gru_attention(h_gru)\n",
        "        \n",
        "        avg_pool = torch.mean(h_gru, 1)\n",
        "        max_pool, _ = torch.max(h_gru, 1)\n",
        "        \n",
        "        conc = torch.cat((h_lstm_atten, h_gru_atten, avg_pool, max_pool), 1)\n",
        "        conc = self.relu(self.linear(conc))\n",
        "        conc = self.dropout(conc)\n",
        "        out = self.out(conc)\n",
        "        \n",
        "        return out\n",
        "        "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAbIvE0v_MaZ"
      },
      "source": [
        "m = NeuralNet()\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTmB4IiPA8-p"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQV3zAzCAoPH"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sjYqj6a_Mdg"
      },
      "source": [
        "def train_model(model, x_train, y_train, x_val, y_val, validate=True):\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    # scheduler = CosineAnnealingLR(optimizer, T_max=5)\n",
        "    # scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "    \n",
        "    train = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "    valid = torch.utils.data.TensorDataset(x_val, y_val)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean').cuda()\n",
        "    best_score = -np.inf\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.\n",
        "        \n",
        "        for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
        "            y_pred = model(x_batch)\n",
        "            \n",
        "            \n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "            \n",
        "        model.eval()\n",
        "        \n",
        "        valid_preds = np.zeros((x_val_fold.size(0)))\n",
        "        \n",
        "        if validate:\n",
        "            avg_val_loss = 0.\n",
        "            for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "                y_pred = model(x_batch).detach()\n",
        "\n",
        "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "                valid_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
        "            search_result = threshold_search(y_val.cpu().numpy(), valid_preds)\n",
        "\n",
        "            val_f1, val_threshold = search_result['f1'], search_result['threshold']\n",
        "            elapsed_time = time.time() - start_time\n",
        "            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t val_f1={:.4f} best_t={:.2f} \\t time={:.2f}s'.format(\n",
        "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_f1, val_threshold, elapsed_time))\n",
        "        else:\n",
        "            elapsed_time = time.time() - start_time\n",
        "            print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
        "                epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
        "    \n",
        "    valid_preds = np.zeros((x_val_fold.size(0)))\n",
        "    \n",
        "    avg_val_loss = 0.\n",
        "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "        y_pred = model(x_batch).detach()\n",
        "\n",
        "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "        valid_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
        "\n",
        "    print('Validation loss: ', avg_val_loss)\n",
        "\n",
        "    test_preds = np.zeros((len(test_loader.dataset)))\n",
        "    \n",
        "    for i, (x_batch,) in enumerate(test_loader):\n",
        "        y_pred = model(x_batch).detach()\n",
        "\n",
        "        test_preds[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
        "    # scheduler.step()\n",
        "    \n",
        "    return valid_preds, test_preds#, test_preds_local\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3imRZ5_Mgy"
      },
      "source": [
        "x_test_cuda = torch.tensor(X_test, dtype=torch.long).cuda()\n",
        "test = torch.utils.data.TensorDataset(x_test_cuda)\n",
        "batch_size = 512\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJeiECHv_VeI"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj5jj7yp_iH7"
      },
      "source": [
        "seed=1029\n",
        "\n",
        "def threshold_search(y_true, y_proba):\n",
        "    best_threshold = 0\n",
        "    best_score = 0\n",
        "    for threshold in tqdm([i * 0.01 for i in range(100)], disable=True):\n",
        "        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n",
        "        if score > best_score:\n",
        "            best_threshold = threshold\n",
        "            best_score = score\n",
        "    search_result = {'threshold': best_threshold, 'f1': best_score}\n",
        "    return search_result\n",
        "\n",
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwIRafp-75jr"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14skTZUy_Vgv",
        "outputId": "4b769960-b419-43ce-802a-527a5da042e7"
      },
      "source": [
        "train_preds = np.zeros(len(train))\n",
        "test_preds = np.zeros((len(test), len(splits)))\n",
        "n_epochs = 5\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "for i, (train_idx, valid_idx) in enumerate(splits):    \n",
        "    x_train_fold = torch.tensor(X_train[train_idx], dtype=torch.long).cuda()\n",
        "    y_train_fold = torch.tensor(y_train[train_idx, np.newaxis], dtype=torch.float32).cuda()\n",
        "    x_val_fold = torch.tensor(X_train[valid_idx], dtype=torch.long).cuda()\n",
        "    y_val_fold = torch.tensor(y_train[valid_idx, np.newaxis], dtype=torch.float32).cuda()\n",
        "    \n",
        "    train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
        "    valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    print(f'Fold {i + 1}')\n",
        "    \n",
        "    seed_everything(seed + i)\n",
        "    model = NeuralNet()\n",
        "    model.cuda()\n",
        "\n",
        "    valid_preds_fold, test_preds_fold = train_model(model,\n",
        "                                                    x_train_fold, \n",
        "                                                    y_train_fold, \n",
        "                                                    x_val_fold, \n",
        "                                                    y_val_fold, validate=False)\n",
        "\n",
        "    train_preds[valid_idx] = valid_preds_fold\n",
        "    test_preds[:, i] = test_preds_fold\n",
        "    "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Epoch 1/5 \t loss=0.1293 \t time=139.47s\n",
            "Epoch 2/5 \t loss=0.1131 \t time=143.40s\n",
            "Epoch 3/5 \t loss=0.1063 \t time=144.48s\n",
            "Epoch 4/5 \t loss=0.0999 \t time=143.61s\n",
            "Epoch 5/5 \t loss=0.0922 \t time=144.56s\n",
            "Validation loss:  0.10503000260380367\n",
            "Fold 2\n",
            "Epoch 1/5 \t loss=0.1290 \t time=143.91s\n",
            "Epoch 2/5 \t loss=0.1135 \t time=144.08s\n",
            "Epoch 3/5 \t loss=0.1066 \t time=144.77s\n",
            "Epoch 4/5 \t loss=0.0993 \t time=144.25s\n",
            "Epoch 5/5 \t loss=0.0915 \t time=144.35s\n",
            "Validation loss:  0.10286797529968153\n",
            "Fold 3\n",
            "Epoch 1/5 \t loss=0.1302 \t time=144.78s\n",
            "Epoch 2/5 \t loss=0.1141 \t time=144.23s\n",
            "Epoch 3/5 \t loss=0.1080 \t time=145.24s\n",
            "Epoch 4/5 \t loss=0.1011 \t time=144.71s\n",
            "Epoch 5/5 \t loss=0.0936 \t time=145.21s\n",
            "Validation loss:  0.09866426580331547\n",
            "Fold 4\n",
            "Epoch 1/5 \t loss=0.1282 \t time=144.84s\n",
            "Epoch 2/5 \t loss=0.1136 \t time=144.08s\n",
            "Epoch 3/5 \t loss=0.1069 \t time=144.27s\n",
            "Epoch 4/5 \t loss=0.0998 \t time=143.95s\n",
            "Epoch 5/5 \t loss=0.0922 \t time=144.49s\n",
            "Validation loss:  0.10106607826082112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zIxzMYE_VjY"
      },
      "source": [
        "search_result = threshold_search(y_train, train_preds)\n",
        "sub['prediction'] = test_preds.mean(1) > search_result['threshold']\n",
        "sub.to_csv(\"submission.csv\", index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4iQLd6xw3GIw",
        "outputId": "f895ff22-106d-4e33-ba1a-354f0f61b7ef"
      },
      "source": [
        "sub = pd.read_csv(\"submission.csv\")\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  prediction\n",
              "0  0000163e3ea7c7a74cd7        True\n",
              "1  00002bd4fb5d505b9161       False\n",
              "2  00007756b4a147d2b0b3       False\n",
              "3  000086e4b7e1c7146103       False\n",
              "4  0000c4c3fbe8785a3090       False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cdLkaPZV_Ed"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}